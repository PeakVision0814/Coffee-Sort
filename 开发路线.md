### ☕ 咖啡智能化分拣系统开发路线图 (Python版)

#### 📅 阶段一：硬件链路与基础驱动验证 (T5.1 - T5.4)

**目标**：确保所有硬件（机械臂、相机、PLC信号）都能通过 Python 单独控制，不涉及业务逻辑。

* **Step 1.1: 机械臂通信测试**
* **任务**：验证 `pymycobot` 与机械臂的串口通讯。
* **代码位置**：`scripts/test_arm.py`
* **关键点**：测试 `get_angles()` 读取是否准确，测试 `send_coords()` 移动是否顺畅，测试夹爪 `set_gripper_value()` 开合。
* **验收标准**：运行脚本，机械臂能点头、摇头、开合夹爪，且无报错。


* **Step 1.2: 摄像头基础流测试**
* **任务**：验证普通 USB 摄像头在 OpenCV 下的稳定性。
* **代码位置**：`scripts/test_camera.py` (新建)
* **关键点**：使用 `cv2.VideoCapture(0)`，确保能以 30fps 以上稳定读取图像，画面无严重畸变。
* **验收标准**：能弹窗显示实时画面，按下 'q' 键正常退出，不卡死。


* **Step 1.3: PLC 信号模拟测试 (IO 握手)**
* **任务**：验证 PC 能否正确读取/发送继电器信号。
* **代码位置**：`modules/plc_comm.py`
* **关键点**：编写 `read_trigger_signal()` 和 `send_done_signal()`。
* **测试方法**：手动短接继电器输入端，看 Python 是否打印 "Trigger received"；Python 发送信号，看继电器灯是否亮起。
* **验收标准**：IO 读写延迟 < 50ms，信号准确无误。



---

#### 📅 阶段二：视觉系统核心开发 (T5.2 - T5.3)

**目标**：解决“眼在手”最核心的问题——把图像里的像素坐标  变成机械臂的物理坐标 。

* **Step 2.1: 相机畸变标定 (Camera Calibration)**
* **任务**：消除普通摄像头的广角畸变。
* **工具**：打印一张棋盘格标定纸。
* **代码位置**：`scripts/calibrate_camera.py`
* **产出**：生成相机内参矩阵，保存至 `config/camera_matrix.npy`。


* **Step 2.2: 手眼标定 (Hand-Eye Calibration) —— 最核心步骤**
* **原理**：确定摄像头中心对应机械臂法兰中心的偏移量，以及像素与毫米的换算比例。
* **方法**：
1. 控制机械臂末端垂直向下，固定高度（例如 Z=250mm）。
2. 在画面中心放一个标记物，记录此时机械臂坐标 。
3. 移动机械臂，让标记物出现在画面四个角，记录对应的机械臂坐标和像素坐标。
4. 通过线性回归算出 `Pixel_per_mm` (像素当量) 和 `Center_Offset` (中心偏差)。


* **代码位置**：`scripts/calibrate_eye.py`
* **产出**：将标定参数写入 `config/calibration.json`。


* **Step 2.3: 识别算法封装**
* **任务**：实现 STag 或颜色识别。
* **代码位置**：`modules/vision.py`
* **逻辑**：
1. `get_frame()` 获取图像。
2. `process_image()` 识别目标中心 。
3. `pixels_to_coords()` 调用标定参数，返回机械臂目标坐标 。


* **验收标准**：把咖啡盒放在不同位置，程序打印出的  与你用尺子量的实际位置误差 < 2mm。



---

#### 📅 阶段三：运动规划与动作封装 (T5.5)

**目标**：让机械臂“盲抓”也能抓得准，且不撞机。

* **Step 3.1: 定义安全点与路径点**
* **任务**：在配置文件中写死关键坐标。
* **代码位置**：`config/settings.py`
* **关键坐标**：
* `HOME_POSE`: 待机观测点（高处）。
* `SAFE_Z`: 安全移动高度（例如 Z=200mm）。
* `BIN_A_POSE`, `BIN_B_POSE`: 成品仓放置点。




* **Step 3.2: 封装抓取动作序列**
* **任务**：编写原子动作函数。
* **代码位置**：`modules/arm_control.py`
* **函数设计**：
* `go_home()`
* `pick_target(x, y)`: 移动到上方 -> 下降 -> 闭合夹爪 -> 上升。
* `place_target(bin_type)`: 移动到对应仓 -> 张开夹爪 -> 回安全位。


* **验收标准**：运行测试脚本，机械臂能流畅完成“空抓”动作，且不撞击桌面。



---

#### 📅 阶段四：主控逻辑与联调 (T5.4 - T5.6)

**目标**：将视觉、机械臂、PLC 串联起来，形成闭环。

* **Step 4.1: 状态机主程序开发**
* **任务**：编写主业务逻辑循环。
* **代码位置**：`main.py`
* **逻辑流**：
```python
while True:
    # 1. 监听 PLC 触发信号
    if plc.read_trigger():
        # 2. 视觉识别
        target = vision.scan()
        if target:
            # 3. 执行抓取
            arm.pick_target(target)
            # 4. 执行放置
            arm.place_target(target.type)
            # 5. 反馈完成信号
            plc.send_done()
        else:
            # 异常处理：没看到东西
            handle_error()

```




* **Step 4.2: 异常处理机制 (看门狗)**
* **任务**：防止摄像头掉线导致程序崩溃。
* **代码位置**：`modules/vision.py`
* **逻辑**：如果 `cap.read()` 失败，自动执行 `cap.release()` 并重新 `cv2.VideoCapture(0)`。


* **Step 4.3: 现场联调**
* **任务**：配合 PLC 工程师进行实物测试。
* **验收标准**：连续运行 20 次，无卡顿、无漏抓、PLC 信号交互正常。



---

#### 📅 阶段五：性能优化与交付 (T5.7)

**目标**：达到 >= 3个/分钟 的指标，提升稳定性。

* **Step 5.1: 节拍优化**
* **策略**：减少 `time.sleep()` 的时间，提高 `send_coords` 的 speed 参数（从 50 提至 80-100）。


* **Step 5.2: 坐标微调**
* **策略**：根据实际抓取偏差，微调 `calibration.json` 中的补偿值。


* **Step 5.3: DeepSeek 接入 (可选/演示用)**
* **任务**：在 `modules/ai_decision.py` 中接入 API，仅用于语音指令解析演示。